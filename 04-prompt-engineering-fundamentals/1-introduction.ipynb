{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook was auto-generated by GitHub Copilot Chat and is meant for initial setup only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.3.1)\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install tiktoken\n",
    "#! pip install openai==0.28.1\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198, 41, 20089, 374, 279, 18172, 11841, 505, 279, 8219, 323, 279, 7928, 304, 279, 25450, 744, 13, 1102, 374, 264, 6962, 14880, 449, 264, 3148, 832, 7716, 52949, 339, 430, 315, 279, 8219, 11, 719, 1403, 9976, 7561, 34902, 3115, 430, 315, 682, 279, 1023, 33975, 304, 279, 25450, 744, 11093, 13, 50789, 374, 832, 315, 279, 72021, 6302, 9621, 311, 279, 19557, 8071, 304, 279, 3814, 13180, 11, 323, 706, 1027, 3967, 311, 14154, 86569, 2533, 1603, 12715, 3925, 13, 1102, 374, 7086, 1306, 279, 13041, 10087, 50789, 8032, 777, 60, 3277, 19894, 505, 9420, 11, 50789, 649, 387, 10107, 3403, 369, 1202, 27000, 3177, 311, 6445, 9621, 35612, 17706, 508, 60, 323, 374, 389, 5578, 279, 4948, 1481, 1315, 478, 5933, 1665, 304, 279, 3814, 13180, 1306, 279, 17781, 323, 50076, 627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\n',\n",
       " b'J',\n",
       " b'upiter',\n",
       " b' is',\n",
       " b' the',\n",
       " b' fifth',\n",
       " b' planet',\n",
       " b' from',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b' and',\n",
       " b' the',\n",
       " b' largest',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' a',\n",
       " b' gas',\n",
       " b' giant',\n",
       " b' with',\n",
       " b' a',\n",
       " b' mass',\n",
       " b' one',\n",
       " b'-th',\n",
       " b'ousand',\n",
       " b'th',\n",
       " b' that',\n",
       " b' of',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b',',\n",
       " b' but',\n",
       " b' two',\n",
       " b'-and',\n",
       " b'-a',\n",
       " b'-half',\n",
       " b' times',\n",
       " b' that',\n",
       " b' of',\n",
       " b' all',\n",
       " b' the',\n",
       " b' other',\n",
       " b' planets',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b' combined',\n",
       " b'.',\n",
       " b' Jupiter',\n",
       " b' is',\n",
       " b' one',\n",
       " b' of',\n",
       " b' the',\n",
       " b' brightest',\n",
       " b' objects',\n",
       " b' visible',\n",
       " b' to',\n",
       " b' the',\n",
       " b' naked',\n",
       " b' eye',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b',',\n",
       " b' and',\n",
       " b' has',\n",
       " b' been',\n",
       " b' known',\n",
       " b' to',\n",
       " b' ancient',\n",
       " b' civilizations',\n",
       " b' since',\n",
       " b' before',\n",
       " b' recorded',\n",
       " b' history',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' named',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Roman',\n",
       " b' god',\n",
       " b' Jupiter',\n",
       " b'.[',\n",
       " b'19',\n",
       " b']',\n",
       " b' When',\n",
       " b' viewed',\n",
       " b' from',\n",
       " b' Earth',\n",
       " b',',\n",
       " b' Jupiter',\n",
       " b' can',\n",
       " b' be',\n",
       " b' bright',\n",
       " b' enough',\n",
       " b' for',\n",
       " b' its',\n",
       " b' reflected',\n",
       " b' light',\n",
       " b' to',\n",
       " b' cast',\n",
       " b' visible',\n",
       " b' shadows',\n",
       " b',[',\n",
       " b'20',\n",
       " b']',\n",
       " b' and',\n",
       " b' is',\n",
       " b' on',\n",
       " b' average',\n",
       " b' the',\n",
       " b' third',\n",
       " b'-b',\n",
       " b'right',\n",
       " b'est',\n",
       " b' natural',\n",
       " b' object',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Moon',\n",
       " b' and',\n",
       " b' Venus',\n",
       " b'.\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate OpenAI API Key Setup\n",
    "\n",
    "Run the code below to verify that your OpenAI endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ['AZURE_OPENAI_KEY'] = \"a756d3e7c1ad4dfbab117c70cf644f68\"\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = \"https://openai-btp-sa.openai.azure.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "openai.api_version = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a completion call to generate an answer\n",
    "print('Sending a test completion job')\n",
    "start_phrase = 'Write a tagline for an ice cream shop. '\n",
    "messages = [{\"role\": \"user\", \"content\": start_phrase}]\n",
    "model=\"gpt-35-turbo\"\n",
    "response = openai.ChatCompletion.create(engine=model, messages=messages, max_tokens=10)\n",
    "#print(response)\n",
    "text = response['choices'][0]['message']['content'].replace('\\n', '').replace(' .', '.').strip()\n",
    "print(start_phrase+text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-35-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.6\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by the dawn's early light\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt, model=\"gpt-35-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Martian War of 2076 - A Lesson Plan\n",
      "\n",
      "Objective: \n",
      "To educate students about the Martian War of 2076, its causes, key events, and consequences, fostering critical thinking, historical analysis, and empathy.\n",
      "\n",
      "Grade Level: \n",
      "High School (9th-12th grade)\n",
      "\n",
      "Duration: \n",
      "2-3 class periods (approximately 90 minutes each)\n",
      "\n",
      "Materials Needed:\n",
      "1. Access to research materials (books, articles, online resources)\n",
      "2. Whiteboard or blackboard\n",
      "3. Markers or chalk\n",
      "4. Handouts (optional)\n",
      "5. Multimedia resources (optional)\n",
      "\n",
      "Lesson Plan:\n",
      "\n",
      "Day 1:\n",
      "\n",
      "Introduction (15 minutes)\n",
      "1. Begin the lesson by engaging students in a brief discussion about science fiction and its influence on society.\n",
      "2. Introduce the topic of the Martian War of 2076, explaining that it is a fictional event but will be studied as if it were real.\n",
      "3. Share the lesson objectives and explain the importance of understanding historical events, even if they are fictional.\n",
      "\n",
      "Causes of the Martian War (30 minutes)\n",
      "1. Divide students into small groups and provide each group with research materials.\n",
      "2. Instruct students to identify and discuss the possible causes of the Martian War of 2076.\n",
      "3. After group discussions, facilitate a class discussion, allowing each group to share their findings.\n",
      "4. Summarize the causes on the board, encouraging students to critically analyze the factors that led to the war.\n",
      "\n",
      "Key Events of the Martian War (45 minutes)\n",
      "1. Provide students with a timeline of the Martian War, highlighting key events.\n",
      "2. Instruct students to work individually or in pairs to research and summarize each event.\n",
      "3. Allow time for students to present their findings to the class, discussing the significance of each event.\n",
      "4. Facilitate a class discussion to analyze the sequence of events and their impact on the war's outcome.\n",
      "\n",
      "Day 2:\n",
      "\n",
      "Consequences of the Martian War (30 minutes)\n",
      "1. Discuss the consequences of the Martian War, both for Earth and Mars.\n",
      "2. Divide students into small groups and assign each group a specific consequence to research.\n",
      "3. Instruct students to create a visual representation (poster, infographic, etc.) highlighting their assigned consequence.\n",
      "4. Allow time for each group to present their findings, discussing the short-term and long-term effects of the war.\n",
      "\n",
      "Analyzing Perspectives (45 minutes)\n",
      "1. Divide students into pairs or small groups.\n",
      "2. Assign each group a specific role, such as a Martian civilian, an Earth soldier, a Martian rebel, or an Earth politician.\n",
      "3. Instruct students to discuss and analyze the war from their assigned perspective, considering motivations, emotions, and experiences.\n",
      "4. Facilitate a class discussion, allowing each group to share their insights and promoting empathy towards different perspectives.\n",
      "\n",
      "Reflection and Discussion (15 minutes)\n",
      "1. Lead a class discussion to reflect on the Martian War of 2076 as a fictional event.\n",
      "2. Encourage students to draw parallels between the Martian War and real historical conflicts, discussing the potential lessons learned.\n",
      "3. Summarize the key takeaways from the lesson and address any remaining questions or concerns.\n",
      "\n",
      "Optional Extension Activities:\n",
      "1. Creative Writing: Ask students to write a short story or a diary entry from the perspective of a character involved in the Martian War.\n",
      "2. Debate: Organize a class debate on the ethical implications of the Martian War, exploring topics such as colonization, resource exploitation, and interplanetary relations.\n",
      "3. Multimedia Presentation: Allow students to create multimedia presentations (videos, slideshows, etc.) summarizing the Martian War and its impact.\n",
      "\n",
      "Assessment:\n",
      "1. Group and individual participation during discussions and activities.\n",
      "2. Quality of research and presentation of key events and consequences.\n",
      "3. Reflection and critical analysis demonstrated in class discussions and written assignments (optional).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is a really big planet that is fifth from the Sun. It is made of gas and is much smaller than the Sun but bigger than all the other planets combined. People have known about Jupiter for a really long time because it is very bright in the night sky. It is named after a god from ancient Rome. Sometimes, Jupiter is so bright that it can make shadows on Earth. It is usually the third-brightest thing we can see at night, after the Moon and Venus.\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a super top-secret, underground, invisible stadium located on Mars. Didn't you hear? They had to take drastic measures to ensure social distancing.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. In which country would you find the Great Barrier Reef?\n",
      "Answer: Australia\n",
      "\n",
      "2. What is the largest country in South America?\n",
      "Answer: Brazil\n",
      "\n",
      "3. Which country is home to Mount Kilimanjaro?\n",
      "Answer: Tanzania\n",
      "\n",
      "4. What is the capital of Canada?\n",
      "Answer: Ottawa\n",
      "\n",
      "5. Name the three largest rivers in the world.\n",
      "Answer: Nile, Amazon, Yangtze\n",
      "\n",
      "6. Which country has the longest coastline in the world?\n",
      "Answer: Canada\n",
      "\n",
      "7. What is the capital city of Spain?\n",
      "Answer: Madrid\n",
      "\n",
      "8. Name the seven continents.\n",
      "Answer: Africa, Antarctica, Asia, Europe, North America, Oceania, South America\n",
      "\n",
      "9. Which country is known as \"The Land Down Under\"?\n",
      "Answer: Australia\n",
      "\n",
      "10. What is the highest mountain in the world?\n",
      "Answer: Mount Everest\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate 10 questions on geography and write also the answers.\"}\n",
    "        #{\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        #{\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        #{\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dalleproduse.blob.core.windows.net/private/images/ebb076f2-5c95-4855-bb4b-b042cb392507/generated_00.png?se=2023-12-02T15%3A22%3A36Z&sig=9dMrFQfX1hvdt61Gl1KXzzaCX0c7P%2BtwLA%2B7K8ocuik%3D&ske=2023-12-07T13%3A19%3A15Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-11-30T13%3A19%3A15Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import httpx\n",
    "import openai\n",
    "\n",
    "\n",
    "class CustomHTTPTransport(httpx.HTTPTransport):\n",
    "    def handle_request(\n",
    "        self,\n",
    "        request: httpx.Request,\n",
    "    ) -> httpx.Response:\n",
    "        if \"images/generations\" in request.url.path and request.url.params[\n",
    "            \"api-version\"\n",
    "        ] in [\n",
    "            \"2023-06-01-preview\",\n",
    "            \"2023-07-01-preview\",\n",
    "            \"2023-08-01-preview\",\n",
    "            \"2023-09-01-preview\",\n",
    "            \"2023-10-01-preview\",\n",
    "        ]:\n",
    "            request.url = request.url.copy_with(path=\"/openai/images/generations:submit\")\n",
    "            response = super().handle_request(request)\n",
    "            operation_location_url = response.headers[\"operation-location\"]\n",
    "            request.url = httpx.URL(operation_location_url)\n",
    "            request.method = \"GET\"\n",
    "            response = super().handle_request(request)\n",
    "            response.read()\n",
    "\n",
    "            timeout_secs: int = 120\n",
    "            start_time = time.time()\n",
    "            while response.json()[\"status\"] not in [\"succeeded\", \"failed\"]:\n",
    "                if time.time() - start_time > timeout_secs:\n",
    "                    timeout = {\"error\": {\"code\": \"Timeout\", \"message\": \"Operation polling timed out.\"}}\n",
    "                    return httpx.Response(\n",
    "                        status_code=400,\n",
    "                        headers=response.headers,\n",
    "                        content=json.dumps(timeout).encode(\"utf-8\"),\n",
    "                        request=request,\n",
    "                    )\n",
    "\n",
    "                time.sleep(int(response.headers.get(\"retry-after\")) or 10)\n",
    "                response = super().handle_request(request)\n",
    "                response.read()\n",
    "\n",
    "            if response.json()[\"status\"] == \"failed\":\n",
    "                error_data = response.json()\n",
    "                return httpx.Response(\n",
    "                    status_code=400,\n",
    "                    headers=response.headers,\n",
    "                    content=json.dumps(error_data).encode(\"utf-8\"),\n",
    "                    request=request,\n",
    "                )\n",
    "\n",
    "            result = response.json()[\"result\"]\n",
    "            return httpx.Response(\n",
    "                status_code=200,\n",
    "                headers=response.headers,\n",
    "                content=json.dumps(result).encode(\"utf-8\"),\n",
    "                request=request,\n",
    "            )\n",
    "        return super().handle_request(request)\n",
    "\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2023-06-01-preview\",\n",
    "    http_client=httpx.Client(\n",
    "        transport=CustomHTTPTransport(),\n",
    "    ),\n",
    ")\n",
    "image = client.images.generate(prompt=\"a cute baby seal\")\n",
    "\n",
    "print(image.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dalleproduse.blob.core.windows.net/private/images/e0ac9e37-166d-44ac-9cf1-d30d7b75f565/generated_00.png?se=2023-12-02T15%3A25%3A16Z&sig=jd%2FDjrDyElRF3i5m6LbTiD7ZA54vWqeeFoWGgUnniqE%3D&ske=2023-12-07T23%3A57%3A18Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-11-30T23%3A57%3A18Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n"
     ]
    }
   ],
   "source": [
    "image = client.images.generate(\n",
    "    prompt='Show me an image of red car of make Volvo and model XC90 parked by a cliff with the sun setting',\n",
    "    size='1024x1024',\n",
    "    n=1\n",
    ")\n",
    "print(image.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dalleproduse.blob.core.windows.net/private/images/8be68660-c275-4907-87e5-4de997618d92/generated_00.png?se=2023-12-02T15%3A28%3A37Z&sig=WrhhzX0mkiAGG2qGG4wG912xzrApQPC0RVVo4FEWjB8%3D&ske=2023-12-07T12%3A13%3A02Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-11-30T12%3A13%3A02Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n"
     ]
    }
   ],
   "source": [
    "image = client.images.generate(\n",
    "    prompt='uno pterodattilo sul cielo di milano',\n",
    "    size='1024x1024',\n",
    "    n=1\n",
    ")\n",
    "print(image.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Your Intuition\n",
    "The above examples give you patterns that you can use to create new prompts (simple, complex, instruction etc.) - try creating other exercises to explore some of the other ideas we've talked about like examples, cues and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt, model=\"gpt-35-turbo\", tokens=1024):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=tokens\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a small village nestled in the heart of a lush green valley.\n"
     ]
    }
   ],
   "source": [
    "# add your completion code\n",
    "prompt = \"Complete the following: Once upon a time there was a\"\n",
    "\n",
    "# make completion\n",
    "completion = get_completion(model=\"gpt-35-turbo\", prompt=prompt, tokens=20)\n",
    "\n",
    "# print response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 1: Chicken Pot Pie\n",
      "Ingredients:\n",
      "- 2 cups cooked chicken, shredded\n",
      "- 2 cups potatoes, peeled and diced\n",
      "- 1 cup carrots, peeled and diced\n",
      "- 1 cup frozen peas\n",
      "- 1/2 cup onion, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 1/4 cup all-purpose flour\n",
      "- 2 cups chicken broth\n",
      "- 1/2 cup milk\n",
      "- 1 teaspoon dried thyme\n",
      "- 1 teaspoon dried parsley\n",
      "- Salt and pepper to taste\n",
      "- 2 sheets of puff pastry\n",
      "\n",
      "Recipe 2: Roasted Chicken with Potatoes and Carrots\n",
      "Ingredients:\n",
      "- 4 chicken thighs\n",
      "- 4 cups potatoes, peeled and quartered\n",
      "- 2 cups carrots, peeled and sliced\n",
      "- 1/4 cup olive oil\n",
      "- 4 cloves garlic, minced\n",
      "- 1 teaspoon dried rosemary\n",
      "- 1 teaspoon dried thyme\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Recipe 3: Chicken and Potato Curry\n",
      "Ingredients:\n",
      "- 2 chicken breasts, cut into bite-sized pieces\n",
      "- 2 cups potatoes, peeled and diced\n",
      "- 1 cup carrots, peeled and sliced\n",
      "- 1 onion, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 1 can coconut milk\n",
      "- 2 tablespoons curry powder\n",
      "- 1 teaspoon turmeric\n",
      "- 1 teaspoon cumin\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro for garnish\n",
      "\n",
      "Recipe 4: Chicken, Potato, and Carrot Stir-Fry\n",
      "Ingredients:\n",
      "- 2 chicken breasts, thinly sliced\n",
      "- 2 cups potatoes, peeled and julienned\n",
      "- 1 cup carrots, peeled and julienned\n",
      "- 1 bell pepper, thinly sliced\n",
      "- 1/2 cup soy sauce\n",
      "- 2 tablespoons honey\n",
      "- 2 tablespoons sesame oil\n",
      "- 2 cloves garlic, minced\n",
      "- 1 teaspoon ginger, grated\n",
      "- 1/4 teaspoon red pepper flakes (optional)\n",
      "- Sesame seeds for garnish\n",
      "\n",
      "Recipe 5: Chicken, Potato, and Carrot Soup\n",
      "Ingredients:\n",
      "- 2 chicken breasts, cooked and shredded\n",
      "- 2 cups potatoes, peeled and diced\n",
      "- 1 cup carrots, peeled and sliced\n",
      "- 1 onion, chopped\n",
      "- 2 cloves garlic, minced\n",
      "- 4 cups chicken broth\n",
      "- 1 cup milk\n",
      "- 1 teaspoon dried thyme\n",
      "- 1 teaspoon dried parsley\n",
      "- Salt and pepper to taste\n",
      "- Fresh parsley for garnish\n"
     ]
    }
   ],
   "source": [
    "# add your completion code\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "# make completion\n",
    "completion = get_completion(model=\"gpt-35-turbo\", prompt=prompt, tokens=1024)\n",
    "\n",
    "# print response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 recipes using chicken, potatoes, and carrots, without garlic:\n",
      "\n",
      "Recipe 1: Baked Chicken with Roasted Vegetables\n",
      "Ingredients:\n",
      "- 4 chicken breasts\n",
      "- 4 medium potatoes, cubed\n",
      "- 4 carrots, sliced\n",
      "- 1 onion, sliced\n",
      "- 2 tablespoons olive oil\n",
      "- 1 teaspoon dried thyme\n",
      "- 1 teaspoon dried rosemary\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Recipe 2: Chicken and Potato Curry\n",
      "Ingredients:\n",
      "- 4 chicken thighs, boneless and skinless\n",
      "- 4 medium potatoes, peeled and cubed\n",
      "- 2 carrots, sliced\n",
      "- 1 onion, chopped\n",
      "- 2 tablespoons vegetable oil\n",
      "- 2 teaspoons curry powder\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 cup coconut milk\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Recipe 3: Chicken, Potato, and Carrot Stir-Fry\n",
      "Ingredients:\n",
      "- 4 chicken breasts, sliced\n",
      "- 4 medium potatoes, peeled and cubed\n",
      "- 2 carrots, sliced\n",
      "- 1 onion, sliced\n",
      "- 2 tablespoons soy sauce\n",
      "- 1 tablespoon oyster sauce\n",
      "- 1 tablespoon honey\n",
      "- 1 tablespoon vegetable oil\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Recipe 4: Chicken, Potato, and Carrot Soup\n",
      "Ingredients:\n",
      "- 4 chicken thighs, bone-in and skin-on\n",
      "- 4 medium potatoes, peeled and cubed\n",
      "- 2 carrots, sliced\n",
      "- 1 onion, chopped\n",
      "- 4 cups chicken broth\n",
      "- 1 teaspoon dried thyme\n",
      "- 1 teaspoon dried parsley\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Recipe 5: Chicken, Potato, and Carrot Skillet\n",
      "Ingredients:\n",
      "- 4 chicken drumsticks\n",
      "- 4 medium potatoes, peeled and cubed\n",
      "- 2 carrots, sliced\n",
      "- 1 onion, chopped\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 teaspoon paprika\n",
      "- 1 teaspoon dried oregano\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Shopping List:\n",
      "- Onion\n",
      "- Olive oil\n",
      "- Dried thyme\n",
      "- Dried rosemary\n",
      "- Salt\n",
      "- Pepper\n",
      "- Curry powder\n",
      "- Ground cumin\n",
      "- Ground coriander\n",
      "- Coconut milk\n",
      "- Vegetable oil\n",
      "- Soy sauce\n",
      "- Oyster sauce\n",
      "- Honey\n",
      "- Chicken broth\n",
      "- Dried parsley\n",
      "- Paprika\n",
      "- Dried oregano\n"
     ]
    }
   ],
   "source": [
    "# add your completion code\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots.\"+\\\n",
    "         \"Per recipe, list all the ingredients used.\"+\\\n",
    "         \"Please remove recipes with garlic as I'm allergic and replace it with something else.\"+\\\n",
    "         \"Also, please produce a shopping list for the recipes, considering I already have chicken, potatoes and carrots at home.\"\n",
    "\n",
    "# make completion\n",
    "completion = get_completion(model=\"gpt-35-turbo\", prompt=prompt, tokens=1024)\n",
    "\n",
    "# print response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
